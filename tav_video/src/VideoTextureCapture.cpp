/*
 *  VideoTextureCapture.cpp
 *  Timeart Visualizer modern OpenGL framework
 *
 *  Created by Sven Hahne on 29.05.11.
 *  Copyright 2011 Sven Hahne. All rights reserved.
 *
 *  Capturing Video from video4linux devices or alike via FFmpeg
 *
 */

#include "VideoTextureCapture.h"



namespace tav {

VideoTextureCapture::VideoTextureCapture(char* device, int initFrameRate)
: cur_frame(0), nrBufferFrames(16), actBuffer(0), textureSize(512),
  dst_pix_fmt(AV_PIX_FMT_BGRA), isRunning(false)
{
	printf("----- VideoCapture init \n");

	texIDs = new GLuint[nrBufferFrames];
	textures = new TextureManager[nrBufferFrames];

	// Register all formats and codecs
	av_register_all();
	avdevice_register_all();
	avformat_network_init();

	const char      formatName[] = "video4linux2";

	pFormatCtx = avformat_alloc_context();

	// set log level
	av_log_set_level(AV_LOG_QUIET);

	// Open video file
	if (avformat_open_input(&pFormatCtx, device, pFormat,  NULL) !=0 )
	{
		printf("can't find open input file %s\n", device);
		return ;
	}

	if (!(pFormat = av_find_input_format(formatName)))
	{
		printf("can't find input format %s\n", formatName);
		return ;
	}

	// Retrieve stream information
	if( avformat_find_stream_info(pFormatCtx, NULL) < 0 )
		std::cerr << "Error while calling avformat_find_stream_info" << std::endl;

	// Dump information about file onto standard error
	av_dump_format(pFormatCtx, 0, device, false);

	// Find the first video stream
	videoStream=-1;
	for(i=0; i<pFormatCtx->nb_streams; i++)
	{
		if(pFormatCtx->streams[i]->codec->codec_type==AVMEDIA_TYPE_VIDEO)
		{
			videoStream=i;
			break;
		}
	}

	if((int)videoStream==-1) std::cout << "Didn't find a video stream" << std::endl;

	// Get a pointer to the codec context for the video stream
	pCodecCtx = pFormatCtx->streams[videoStream]->codec;

	// Find the decoder for the video stream
	pCodec = avcodec_find_decoder(pCodecCtx->codec_id);
	if(pCodec==NULL) std::cerr << "Codec not found" << std::endl;



	// Open codec
	if( avcodec_open2( pCodecCtx, pCodec, NULL ) < 0 ) std::cout << "Could not open codec" << std::endl;

	// Hack to correct wrong frame rates that seem to be generated by some codecs
	if(pCodecCtx->time_base.num>1000 && pCodecCtx->time_base.den==1)
		pCodecCtx->time_base.den=1000;

	frameRate = pCodecCtx->time_base.den / pCodecCtx->ticks_per_frame;

	// Allocate video frame
	pFrame=av_frame_alloc();
	last_frame = -1;


	stream_index = pFormatCtx->streams[videoStream]->index;
	stream_width = pCodecCtx->width;
	stream_height = pCodecCtx->height;
	std::cout << "Video width: " << stream_width << " stream_height: " << stream_height << std::endl;

	stream_nr = videoStream;

	// Allocate an AVFrame structure
	pFrameRGB = new AVFrame*[nrBufferFrames];
	for (int i=0; i<nrBufferFrames; i++)
	{
		pFrameRGB[i] = av_frame_alloc();
		if(pFrameRGB[i] == NULL) std::cout << "Codec not allocate frame" << std::endl;
	}


	// Determine required buffer size and allocate buffer
//	numBytes = avpicture_get_size(dst_pix_fmt, pCodecCtx->width, pCodecCtx->height);
	numBytes = av_image_get_buffer_size(dst_pix_fmt, pCodecCtx->width, pCodecCtx->height, 1);
	frame_num_bytes = numBytes;

	buffer = new uint8_t*[nrBufferFrames];

	for (int i=0; i<nrBufferFrames; i++)
	{
		buffer[i] = new uint8_t[numBytes];

		// Assign appropriate parts of buffer to image planes in pFrameRGB
//		avpicture_fill((AVPicture *)pFrameRGB[i], buffer[i], dst_pix_fmt,
//				pCodecCtx->width, pCodecCtx->height);
		av_image_fill_arrays (pFrameRGB[i]->data, pFrameRGB[i]->linesize, buffer[i], dst_pix_fmt, pCodecCtx->width, pCodecCtx->height, 1);
	}

	img_convert_ctx = sws_getContext(pCodecCtx->width, pCodecCtx->height,
			pCodecCtx->pix_fmt,
			pCodecCtx->width, pCodecCtx->height,
			dst_pix_fmt,
			SWS_FAST_BILINEAR, //SWS_BICUBIC,
			NULL, NULL, NULL);
	if (img_convert_ctx == NULL) {
		std::cout << "Cannot initialize the conversion context" << std::endl;
	}

	for (int i=0;i<nrBufferFrames;i++)
	{
		texIDs[i] = textures[i].allocate(stream_width, stream_height, GL_RGBA8, GL_RGBA, GL_TEXTURE_2D);
		textures[i].setWraping(GL_CLAMP_TO_BORDER);

		// pre buffering
		double time = 1.f / static_cast<float>(initFrameRate) * static_cast<float>(i);
		get_frame_pointer(time, true);
		nrFramesBuffered++;
	}

	internTime = 1.f / static_cast<float>(initFrameRate) * static_cast<float>(nrBufferFrames);

	std::cout << "-------- VideoCaptureInitDone" << std::endl;

	isRunning = true;
	m_Thread = new std::thread(&VideoTextureCapture::processQueue, this);
}

//------------------------------------------------------------------------------------

VideoTextureCapture::~VideoTextureCapture()
{
	// Free the RGB image
	for (int i=0; i<nrBufferFrames; i++)
	{
		delete [] buffer[i];
	}
	delete [] buffer;

	av_free(pFrameRGB);

	// Free the YUV frame
	av_free(pFrame);

	// Close the codec
	avcodec_close(pCodecCtx);

	// Close the video file
	avformat_close_input(&pFormatCtx);
}

//------------------------------------------------------------------------------------

void VideoTextureCapture::get_frame_pointer(double time, bool loop)
{
	int frame;

	frame = static_cast<int> (time * pFormatCtx->streams[videoStream]->time_base.den);
	if (frame < 0) frame = 0;

	if (loop) {
		frame = frame % stream_total_frames;
	} else
	{
		if (frame >= stream_total_frames)
			frame = stream_total_frames - 1;
	}

	cur_frame = frame;

	// seek position
	int ret = av_seek_frame(pFormatCtx, stream_index, frame, AVSEEK_FLAG_BACKWARD);
//	if (ret < 0)
//		std::cout << "could not seek to position" << ((double) 10 / AV_TIME_BASE) << std::endl;
//
	AVPacket packet;

	//        printf("schreibe frame auf stelle %d, frame: %d  \n", actBuffer, frame);

	//if (av_read_frame(pFormatCtx, &packet) > 0 )
	while (av_read_frame(pFormatCtx, &packet) >= 0)
	{
		// Is this a packet from the video stream?
		if (packet.stream_index == stream_nr) {
			// Decode video frame
			int frameFinished;

			avcodec_decode_video2(pCodecCtx, pFrame, &frameFinished, &packet);

			// Did we get a video frame?
			if(frameFinished) {
				sws_scale(img_convert_ctx,
						((AVPicture*)pFrame)->data, ((AVPicture*)pFrame)->linesize, 0, pCodecCtx->height,
						((AVPicture *)pFrameRGB[actBuffer])->data, ((AVPicture *)pFrameRGB[actBuffer])->linesize);

				// Free the packet that was allocated by av_read_frame
				av_packet_unref(&packet);
				break;
			}
		}
		// Free the packet that was allocated by av_read_frame
		av_packet_unref(&packet);
	}

	last_frame = frame;
	//        }

	// actBuffer wird linear hochgezählt
	actBuffer = (actBuffer + 1) % nrBufferFrames;

	//  printf("zähle actbuf hoch %d \n", actBuffer);

}

//------------------------------------------------------------------------------------

void VideoTextureCapture::stopReset()
{
	internTime = 0;
}

//------------------------------------------------------------------------------------

void VideoTextureCapture::updateDt(double newDt, bool startStop)
{
	double useDt = 1.0 / 60.0;
	if (newDt != 0) useDt = newDt;

	// brute force methoden zum neustarten, nicht dauerhaft...

	// wenn stop aufgerufen, setze die counter zurück und fülle den buffer mit
	// den ersten frames
	if (!startStop)
	{
		if (isRunning)
		{
			requestStop = true;

			// halte an
			join();

			// setze die zeit und counter zurück
			internTime = 0.0;
			nrFramesBuffered = 0;
			readBuffer = nrBufferFrames -1;
			waitReadBuf = 0;
			waitReadBuf = nrBufferFrames -1;
			actBuffer = 1;

			// buffere die ersten paar frames
			for (int i=0;i<nrBufferFrames;i++)
			{
				// pre buffering
				double time = static_cast<float>(useDt) * static_cast<float>(i);
				get_frame_pointer(time, true);
			}

			nrFramesBuffered = nrBufferFrames;
			internTime = static_cast<float>(useDt) * static_cast<float>(nrBufferFrames-1);
		}
	} else
	{
		// starte video neu
		//if (!isRunning) start(0);
	}

	actDt = useDt;
}


//------------------------------------------------------------------------------------

void VideoTextureCapture::join()
{
	isRunning = false;
	m_Thread->join();
	delete m_Thread;
}

//------------------------------------------------------------------------------------

void VideoTextureCapture::processQueue()
{
	while (isRunning)
	{
		// schau nach ob eine neuer Frame gebraucht wird
		if ( nrFramesBuffered < nrBufferFrames )
		{
			//mutex.lock();

			// zähle interne Zeit hoch
			internTime += actDt;

			// hole den Frame, der zur Zeit gehört
			get_frame_pointer(internTime);

			// zähle die anzahl gepufferter frames hoch
			nrFramesBuffered++;

			//mutex.unlock();

		} else
		{
			std::this_thread::sleep_for(std::chrono::milliseconds(4));
		}
	}
}

//------------------------------------------------------------------------------------

void VideoTextureCapture::loadFrameToTexture()
{
	//	glEnable(GL_TEXTURE_2D);

	mutex.lock();

	// printf("lade textur frame nr %d \n",  stream_width,   stream_height);

	if (isRunning)
	{
		readBuffer = (actBuffer -1 +nrBufferFrames) % nrBufferFrames;

		glBindTexture(GL_TEXTURE_2D, texIDs[0]);
		glTexSubImage2D(GL_TEXTURE_2D,             // target
				0,                          // First mipmap level
				0, 0,                       // x and y offset
				stream_width,              // width and height
				stream_height,
				GL_BGRA,
				GL_UNSIGNED_BYTE,
				pFrameRGB[readBuffer]->data[0]);

		//readBuffer = (readBuffer + 1) % nrBufferFrames;

		// frame wurde geholt, zähle die anzahl gepufferter frames runter
		nrFramesBuffered = nrFramesBuffered -1;

		if (nrBufferFrames < 0) printf("buffer underun!!\n");

	} else {

		glBindTexture(GL_TEXTURE_2D, texIDs[0]);
		glTexSubImage2D(GL_TEXTURE_2D,             // target
				0,                          // First mipmap level
				0, 0,                       // x and y offset
				stream_width,              // width and height
				stream_height,
				GL_BGRA,
				GL_UNSIGNED_BYTE,
				pFrameRGB[waitReadBuf]->data[0]);
	}

	mutex.unlock();
}
}
